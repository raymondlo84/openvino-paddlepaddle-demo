{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0d9296-7fa6-4025-aedf-d2a19b05ff0d",
   "metadata": {},
   "source": [
    "# PaddleOCR with OpenVINO\n",
    "\n",
    "This demo shows how to run PaddleOCR (Lite) model on OpenVINO natively. Instead of exporting the PaddlePaddle model to ONNX and then create the Intermediate Representation (IR) format through OpenVINO optimizer, we can now read direct from the Paddle Model without any conversions.\n",
    "\n",
    "Authors: \n",
    "Zhuo Wu, PhD (OpenVINO Edge AI Software Evangelist - Intel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a53f7-e1c5-4aca-879f-da2dd081b989",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run Paddle Detection with OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9486a04-b8bb-4bf5-9e13-845f2143a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path\n",
    "import sys\n",
    "import json\n",
    "import urllib.request\n",
    "import cv2\n",
    "import numpy as np\n",
    "import paddle\n",
    "import math\n",
    "import time\n",
    "import collections\n",
    "\n",
    "from openvino.inference_engine import IENetwork, IECore, ExecutableNetwork\n",
    "from IPython import display\n",
    "from PIL import Image, ImageDraw\n",
    "import copy\n",
    "\n",
    "import logging\n",
    "import imghdr\n",
    "from shapely.geometry import Polygon\n",
    "import pyclipper\n",
    "\n",
    "sys.path.append(\"/home/wu/openvino_notebooks/notebooks/utils\")\n",
    "import notebook_utils as utils\n",
    "from pre_post_processing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541150c-0f98-41c6-a97c-97acb26efd2f",
   "metadata": {},
   "source": [
    "### Load the Network for Paddle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c5c83a-961c-4d98-8b20-5e96c8ef71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model_dir = \"/home/wu/PaddleOCR/inference/ch_ppocr_mobile_v2.0_det_infer\"\n",
    "det_model_file_path = det_model_dir + \"/inference.pdmodel\"\n",
    "det_params_file_path = det_model_dir + \"/inference.pdiparams\"\n",
    "\n",
    "det_ie = IECore()\n",
    "det_net = det_ie.read_network(det_model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5c940-626c-4cf7-a90f-833200969846",
   "metadata": {},
   "source": [
    "### Load the Network for Paddle Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0a07a-8186-47b5-ad95-f104a84d13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_model_dir = \"/home/wu/PaddleOCR/inference/ch_ppocr_mobile_v2.0_rec_infer\"\n",
    "rec_model_file_path = rec_model_dir + \"/inference.pdmodel\"\n",
    "rec_params_file_path = rec_model_dir + \"/inference.pdiparams\"\n",
    "\n",
    "rec_ie = IECore()\n",
    "rec_net = rec_ie.read_network(rec_model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a1a11-faec-41af-bf43-08b90d28cec3",
   "metadata": {},
   "source": [
    "### Preprocessing and post processing image functions for text detection and recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc8364-109b-4a32-b12b-bcb85f23b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(input_image, size):\n",
    "    img = cv2.resize(input_image, (size,size))\n",
    "    img = np.transpose(img, [2,0,1]) / 255\n",
    "    img = np.expand_dims(img, 0)\n",
    "    ##NormalizeImage: {mean: [0.485, 0.456, 0.406], std: [0.229, 0.224, 0.225], is_scale: True}\n",
    "    img_mean = np.array([0.485, 0.456,0.406]).reshape((3,1,1))\n",
    "    img_std = np.array([0.229, 0.224, 0.225]).reshape((3,1,1))\n",
    "    img -= img_mean\n",
    "    img /= img_std\n",
    "    return img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b1cfc-07b4-484b-b8da-5dbdcdfcfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text_det_res(dt_boxes, img_path):\n",
    "    #src_im = cv2.imread(img_path)\n",
    "    src_im = img_path\n",
    "    for box in dt_boxes:\n",
    "        box = np.array(box).astype(np.int32).reshape(-1, 2)\n",
    "        cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n",
    "    return src_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329d709-14bc-45aa-a1d7-d0d6d608933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess for Paddle Recognition\n",
    "def resize_norm_img(img, max_wh_ratio):\n",
    "        rec_image_shape = [3, 32, 320]\n",
    "        imgC, imgH, imgW = rec_image_shape\n",
    "        assert imgC == img.shape[2]\n",
    "        character_type = \"ch\"\n",
    "        if character_type == \"ch\":\n",
    "            imgW = int((32 * max_wh_ratio))\n",
    "        h, w = img.shape[:2]\n",
    "        ratio = w / float(h)\n",
    "        if math.ceil(imgH * ratio) > imgW:\n",
    "            resized_w = imgW\n",
    "        else:\n",
    "            resized_w = int(math.ceil(imgH * ratio))\n",
    "        resized_image = cv2.resize(img, (resized_w, imgH))\n",
    "        resized_image = resized_image.astype('float32')\n",
    "        resized_image = resized_image.transpose((2, 0, 1)) / 255\n",
    "        resized_image -= 0.5\n",
    "        resized_image /= 0.5\n",
    "        padding_im = np.zeros((imgC, imgH, imgW), dtype=np.float32)\n",
    "        padding_im[:, :, 0:resized_w] = resized_image\n",
    "        return padding_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d3695c-42c3-43d3-8472-9f16913182bf",
   "metadata": {},
   "source": [
    "### Main processing function for PaddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b68ee-bd25-4dd8-9e87-3fe6971c6e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define main function for PaddleOCR\n",
    "def run_paddle_ocr(source=0, flip=False, use_popup=False):\n",
    "    # create video player to play with target fps\n",
    "    player = utils.VideoPlayer(source=source, flip=flip, fps=30)\n",
    "    \n",
    "    #Start video capturing\n",
    "    player.start()\n",
    "    try:\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(winname=title, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        while True:\n",
    "            # grab the frame\n",
    "            frame1 = player.next()\n",
    "            if frame1 is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            else:    \n",
    "                #Filp the image otherwise the recognition result is wrong\n",
    "                frame = cv2.flip(frame1,1)\n",
    "                image_file = frame\n",
    "                test_image = image_preprocess(image_file,640)\n",
    "\n",
    "                # pdmodel might be dynamic shape, this will reshape based on the input\n",
    "                input_key = list(det_net.input_info.items())[0][0] # 'inputs'\n",
    "                det_net.reshape({input_key: test_image.shape})\n",
    "                det_exec_net = det_ie.load_network(det_net, 'CPU') \n",
    "\n",
    "                # measure processing time\n",
    "                start_time = time.time()\n",
    "                #perform the inference step\n",
    "                output = det_exec_net.infer({input_key: test_image})\n",
    "                stop_time = time.time()\n",
    "                result_ie = list(output.values())\n",
    "\n",
    "                # Postprocessing for Paddle Detection\n",
    "                ori_im = image_file.copy()\n",
    "                data = {'image': image_file}\n",
    "                data_resize = DetResizeForTest(data)\n",
    "                data_norm = NormalizeImage(data_resize)\n",
    "                data_list = []\n",
    "                keep_keys =  ['image', 'shape']\n",
    "                for key in keep_keys:\n",
    "                    data_list.append(data[key])\n",
    "                img, shape_list = data_list\n",
    "\n",
    "                shape_list = np.expand_dims(shape_list, axis=0)\n",
    "                pred = result_ie[0]      \n",
    "                if isinstance(pred, paddle.Tensor):\n",
    "                    pred = pred.numpy()\n",
    "                pred = pred[:, 0, :, :]\n",
    "                segmentation = pred > 0.3\n",
    "\n",
    "                boxes_batch = []\n",
    "                for batch_index in range(pred.shape[0]):\n",
    "                    src_h, src_w, ratio_h, ratio_w = shape_list[batch_index]\n",
    "                    mask = segmentation[batch_index]\n",
    "                    boxes, scores = boxes_from_bitmap(pred[batch_index], mask,src_w, src_h)\n",
    "                    boxes_batch.append({'points': boxes})\n",
    "                post_result = boxes_batch\n",
    "                dt_boxes = post_result[0]['points']\n",
    "\n",
    "                dt_boxes = filter_tag_det_res(dt_boxes, ori_im.shape)\n",
    "                #Draw boxes on detected text\n",
    "                src_im = draw_text_det_res(dt_boxes, image_file)\n",
    "\n",
    "                processing_times.append(stop_time - start_time)\n",
    "                # use processing times from last 200 frames\n",
    "                if len(processing_times) > 200:\n",
    "                    processing_times.popleft()\n",
    "\n",
    "                #Visualize Paddle detecion results\n",
    "                _, f_width = frame.shape[:2]\n",
    "                # mean processing time [ms]\n",
    "                processing_time = np.mean(processing_times) * 1000\n",
    "                cv2.putText(img=src_im, text=f\"Inference time: {processing_time:.1f}ms\", org=(20, 40),\n",
    "                            fontFace=cv2.FONT_HERSHEY_COMPLEX, fontScale=f_width / 1000,\n",
    "                            color=(0, 0, 255), thickness=1, lineType=cv2.LINE_AA)\n",
    "\n",
    "                # use this workaround if there is flickering\n",
    "                if use_popup:\n",
    "                    cv2.imshow(winname=title, mat=frame)\n",
    "                    key = cv2.waitKey(1)\n",
    "                    # escape = 27\n",
    "                    if key == 27:\n",
    "                        break\n",
    "                else:\n",
    "                    # encode numpy array to jpg\n",
    "                    _, encoded_img = cv2.imencode(ext=\".jpg\", img=src_im,\n",
    "                                                    params=[cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "                    # create IPython image\n",
    "                    i = display.Image(data=encoded_img)\n",
    "                    # display the image in this notebook\n",
    "                    display.clear_output(wait=True)\n",
    "                    display.display(i)\n",
    "\n",
    "                #Preprocess detection results for recognition\n",
    "                dt_boxes = sorted_boxes(dt_boxes)\n",
    "                img_crop_list = []   \n",
    "                if dt_boxes != []:\n",
    "                    for bno in range(len(dt_boxes)):\n",
    "                        tmp_box = copy.deepcopy(dt_boxes[bno])\n",
    "                        img_crop = get_rotate_crop_image(ori_im, tmp_box)\n",
    "                        img_crop_list.append(img_crop)\n",
    "\n",
    "                    #Recognition starts from here\n",
    "                    img_num = len(img_crop_list)\n",
    "                    # Calculate the aspect ratio of all text bars\n",
    "                    width_list = []\n",
    "                    for img in img_crop_list:\n",
    "                        width_list.append(img.shape[1] / float(img.shape[0]))\n",
    "                    # Sorting can speed up the recognition process\n",
    "                    indices = np.argsort(np.array(width_list))\n",
    "                    rec_res = [['', 0.0]] * img_num\n",
    "                    rec_batch_num = 6\n",
    "                    batch_num = rec_batch_num\n",
    "                    rec_processing_times = 0\n",
    "\n",
    "                    #For each detected text box, run inference for text recognition\n",
    "                    for beg_img_no in range(0, img_num, batch_num):\n",
    "                        end_img_no = min(img_num, beg_img_no + batch_num)\n",
    "\n",
    "                        norm_img_batch = []\n",
    "                        max_wh_ratio = 0\n",
    "                        for ino in range(beg_img_no, end_img_no):\n",
    "                            h, w = img_crop_list[indices[ino]].shape[0:2]\n",
    "                            wh_ratio = w * 1.0 / h\n",
    "                            max_wh_ratio = max(max_wh_ratio, wh_ratio)\n",
    "                        for ino in range(beg_img_no, end_img_no):\n",
    "                            norm_img = resize_norm_img(img_crop_list[indices[ino]],max_wh_ratio)\n",
    "                            norm_img = norm_img[np.newaxis, :]\n",
    "                            norm_img_batch.append(norm_img)\n",
    "\n",
    "                        norm_img_batch = np.concatenate(norm_img_batch)\n",
    "                        norm_img_batch = norm_img_batch.copy()\n",
    "\n",
    "                        # pdmodel might be dynamic shape, this will reshape based on the input\n",
    "                        input_key = list(rec_net.input_info.items())[0][0] # 'inputs'\n",
    "                        rec_net.reshape({input_key: norm_img_batch.shape})\n",
    "                        #Load the Paddle recognition network on CPU\n",
    "                        rec_exec_net = rec_ie.load_network(rec_net, 'CPU') \n",
    "\n",
    "                        #Run inference for text recognition \n",
    "                        for index in range(len(norm_img_batch)):\n",
    "                            output = rec_exec_net.infer({input_key: norm_img_batch})\n",
    "                        result_ie = list(output.values())\n",
    "                        preds = result_ie[0]\n",
    "                        #Postprocessing recognition results\n",
    "                        postprocess_op = build_post_process(postprocess_params)\n",
    "                        rec_result = postprocess_op(preds)\n",
    "                        for rno in range(len(rec_result)):\n",
    "                            rec_res[indices[beg_img_no + rno]] = rec_result[rno]\n",
    "                    print(rec_res)\n",
    "\n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        # stop capturing\n",
    "        player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8855f-418a-4bda-8799-0953dda895c5",
   "metadata": {},
   "source": [
    "## Run Live PaddleOCR with OpenVINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc274952-19aa-480d-ba50-a1146a89771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_paddle_ocr(source=0, flip=True, use_popup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c9d077-70df-4a28-a372-7ee5168f6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test OCR results on video file\n",
    "\n",
    "#video_file = \"test1.mp4\"\n",
    "#source = video_file\n",
    "#player = utils.VideoPlayer(source=source, flip=False, fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openvino_env",
   "language": "python",
   "name": "openvino_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
